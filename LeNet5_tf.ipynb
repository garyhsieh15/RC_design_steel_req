{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LeNet5_tf.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMOTROT82YKHcWepijkMe+z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/garyhsieh15/RC_design_steel_req/blob/master/LeNet5_tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCOk9ml2zBrU"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ey-FLOLzRiQ"
      },
      "source": [
        "%cd /content/drive/MyDrive/work/NCKU/10902/dl/HW04/dl04"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edSEw403TF1J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c520908-5ab1-4c29-c8ff-d6d86fc48a83"
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "(xtrain, ytrain), (xtest, ytest) = tf.keras.datasets.cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 11s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tO9xDNVkTOyk"
      },
      "source": [
        "print(\"xtrain.shape: \\n\", xtrain.shape)\n",
        "print(\"xtrain: \\n\", xtrain)\n",
        "print(\"xtrain[0].shape: \\n\", xtrain[0].shape)\n",
        "print(\"xtrain[0]: \\n\", xtrain[0])\n",
        "print(\"xtrain[0][0]: \\n\", xtrain[0][0])\n",
        "aaa = xtrain.reshape(-1, 32, 32, 3)\n",
        "bbb = aaa.astype('float32')\n",
        "print(\"aaa: \\n\", aaa[0][0])\n",
        "print(\"aaa.shape: \\n\", aaa.shape)\n",
        "print(\"bbb[0][0]: \\n\", bbb[0][0])\n",
        "print(\"bbb[0][0].shape: \\n\", bbb[0][0].shape)\n",
        "print(\"type(aaa) and type(bbb): \\n\", type(aaa), type(bbb))\n",
        "#print(\"xtrain.reshape(-1, 32, 32, 3): \\n\", xtrain.reshape(-1, 32, 32, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j42nUsxCna8g"
      },
      "source": [
        "print(\"ytrain: \\n\", ytrain)\n",
        "print(\"ytrain.shape: \\n\", ytrain.shape)\n",
        "print(\"ytrain[0]: \\n\", ytrain[0])\n",
        "print(\"ytrain[1]: \\n\", ytrain[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjgAZY_Dr9T_"
      },
      "source": [
        "print(\"one: \\n\", xtrain.reshape(-1, 32, 32, 3))\n",
        "print(\"two: \\n\", xtrain.reshape(-1, 32, 32, 3).astype('float32') / 255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSATjA_H7cvK",
        "outputId": "69fa6143-13dc-4b5a-f63b-5e53cfa55d36"
      },
      "source": [
        "#import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "def load_data(num_classes=10):\n",
        "    (xtrain, ytrain), (xtest, ytest) = tf.keras.datasets.cifar10.load_data()\n",
        "    xtrain = xtrain.reshape(-1, 32, 32, 3).astype('float32') / 255\n",
        "    #xtrain = xtrain.reshape(-1, 64, 64, 3).astype('float32') / 255\n",
        "    xtest = xtest.reshape(-1, 32, 32, 3).astype('float32') / 255\n",
        "    #xtest = xtest.reshape(-1, 64, 64, 3).astype('float32') / 255\n",
        "    ytrain = np.eye(num_classes)[ytrain.reshape(-1)] # one hot encoding\n",
        "    ytest = np.eye(num_classes)[ytest.reshape(-1)]   # one hot encoding\n",
        "    return xtrain, ytrain, xtest, ytest\n",
        "\n",
        "def next_batch(batch_size, data, labels):\n",
        "    idx = np.arange(0 , len(data))\n",
        "    np.random.shuffle(idx)\n",
        "    idx = idx[:batch_size]\n",
        "    data_shuffle = [data[i] for i in idx]\n",
        "    labels_shuffle = [labels[i] for i in idx]\n",
        "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68YaASwMTldl",
        "outputId": "8caa27ff-975e-4123-d526-705f83f20c94"
      },
      "source": [
        "xtrain, ytrain, xtest, ytest = load_data()\n",
        "print(\"xtrain.shape: \\n\", xtrain.shape)\n",
        "print(\"ytrain.shape: \\n\", ytrain.shape)\n",
        "print(\"xtest.shape: \\n\", xtest.shape)\n",
        "print(\"ytest.shape: \\n\", ytest.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n",
            "xtrain.shape: \n",
            " (50000, 32, 32, 3)\n",
            "ytrain.shape: \n",
            " (50000, 10)\n",
            "xtest.shape: \n",
            " (10000, 32, 32, 3)\n",
            "ytest.shape: \n",
            " (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOgYjxO87829",
        "outputId": "43d86eb1-a00e-4263-e92a-051d104cf1f0"
      },
      "source": [
        "xtrain, ytrain, xtest, ytest = load_data()\n",
        "\n",
        "# Parameters\n",
        "num_epoch = 4000\n",
        "batch_size = 128\n",
        "\n",
        "# layer 0: input data\n",
        "x = tf.placeholder(\"float\", [None,32,32,3])\n",
        "#x = tf.placeholder(\"float\", [None,64,64,3])\n",
        "y = tf.placeholder(\"float\", [None,10])\n",
        "\n",
        "# layer 1: convolution\n",
        "# filter size = 5x5, input channel = 1, output channel = 32\n",
        "conv1_w = tf.get_variable(\"conv1_w\", [5,5,3,32], initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
        "#conv1_w = tf.get_variable(\"conv1_w\", [5,5,3,64], initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
        "conv1_b = tf.get_variable(\"conv1_b\", [32], initializer=tf.constant_initializer(value=0))\n",
        "#conv1_b = tf.get_variable(\"conv1_b\", [64], initializer=tf.constant_initializer(value=0))\n",
        "conv1 = tf.nn.conv2d(x, conv1_w, strides=[1,1,1,1], padding='SAME')\n",
        "relu1 = tf.nn.relu( tf.nn.bias_add(conv1, conv1_b) )\n",
        "\n",
        "# layer 2: max pool\n",
        "# filter size = 2x2, stride = 2\n",
        "pool1 = tf.nn.max_pool(relu1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
        "\n",
        "# layer 3: convolution\n",
        "# filter size = 5x5, input channel = 32, output channel = 64\n",
        "conv2_w = tf.get_variable(\"conv2_w\", [5,5,32,64], initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
        "#conv2_w = tf.get_variable(\"conv2_w\", [5,5,64,64], initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
        "conv2_b = tf.get_variable(\"conv2_b\", [64], initializer=tf.constant_initializer(value=0))\n",
        "conv2 = tf.nn.conv2d(pool1, conv2_w, strides=[1,1,1,1], padding='SAME')\n",
        "relu2 = tf.nn.relu( tf.nn.bias_add(conv2, conv2_b) )\n",
        "\n",
        "# layer 4: max pool\n",
        "pool2 = tf.nn.max_pool(relu2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
        "\n",
        "# layer 5: fully connected\n",
        "fc1_w = tf.get_variable(\"fc1_w\", [8 * 8 * 64, 1024], initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
        "fc1_b = tf.get_variable(\"fc1_b\", [1024], initializer=tf.constant_initializer(value=0.1))\n",
        "pool2_vector = tf.reshape(pool2, [-1, 8 * 8 * 64])\n",
        "fc1 = tf.nn.relu( tf.matmul(pool2_vector, fc1_w) + fc1_b )\n",
        "\n",
        "# dropout layer\n",
        "fc1_dropout = tf.nn.dropout(fc1, 1.0)\n",
        "\n",
        "# layer 6: fully connected\n",
        "fc2_w = tf.get_variable(\"fc2_w\", [1024, 10], initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
        "fc2_b = tf.get_variable(\"fc2_b\", [10], initializer=tf.constant_initializer(value=0.1))\n",
        "y_hat = tf.matmul(fc1_dropout, fc2_w) + fc2_b\n",
        "\n",
        "# layer 7: softmax, output layer\n",
        "pred = tf.nn.softmax(y_hat)\n",
        "\n",
        "# define loss and optimizer\n",
        "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=y_hat, labels=y))\n",
        "optimizer = tf.train.AdamOptimizer()\n",
        "train_op = optimizer.minimize(loss_op)\n",
        "\n",
        "# evaluate model\n",
        "correct = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for epoch in range(num_epoch):\n",
        "        xbatch, ybatch = next_batch(batch_size, xtrain, ytrain)\n",
        "        sess.run(train_op, feed_dict={x: xbatch, y: ybatch})\n",
        "\n",
        "        if ((epoch + 1) % 100 == 0):\n",
        "            loss, acc = sess.run([loss_op, accuracy], feed_dict={x: xtest, y: ytest})\n",
        "            print(\"epoch \" + str(epoch+1) + \", loss= \" + \"{:.4f}\".format(loss) + \", acc= \" + \"{:.3f}\".format(acc))\n",
        "\n",
        "    # Calculate accuracy for MNIST test images\n",
        "    acc = sess.run(accuracy, feed_dict={x: xtest, y: ytest})\n",
        "    print('test acc=' + '{:.3f}'.format(acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 11s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "epoch 100, loss= 1.6028, acc= 0.430\n",
            "epoch 200, loss= 1.4772, acc= 0.483\n",
            "epoch 300, loss= 1.3210, acc= 0.528\n",
            "epoch 400, loss= 1.2645, acc= 0.556\n",
            "epoch 500, loss= 1.1930, acc= 0.581\n",
            "epoch 600, loss= 1.1862, acc= 0.589\n",
            "epoch 700, loss= 1.1220, acc= 0.609\n",
            "epoch 800, loss= 1.1404, acc= 0.602\n",
            "epoch 900, loss= 1.1177, acc= 0.619\n",
            "epoch 1000, loss= 1.0425, acc= 0.646\n",
            "epoch 1100, loss= 1.0526, acc= 0.644\n",
            "epoch 1200, loss= 1.0447, acc= 0.651\n",
            "epoch 1300, loss= 1.0964, acc= 0.641\n",
            "epoch 1400, loss= 1.0592, acc= 0.659\n",
            "epoch 1500, loss= 1.0940, acc= 0.650\n",
            "epoch 1600, loss= 1.0930, acc= 0.657\n",
            "epoch 1700, loss= 1.0601, acc= 0.672\n",
            "epoch 1800, loss= 1.0982, acc= 0.668\n",
            "epoch 1900, loss= 1.0853, acc= 0.662\n",
            "epoch 2000, loss= 1.1182, acc= 0.668\n",
            "epoch 2100, loss= 1.1293, acc= 0.664\n",
            "epoch 2200, loss= 1.1129, acc= 0.672\n",
            "epoch 2300, loss= 1.1908, acc= 0.665\n",
            "epoch 2400, loss= 1.1431, acc= 0.677\n",
            "epoch 2500, loss= 1.2142, acc= 0.672\n",
            "epoch 2600, loss= 1.2412, acc= 0.672\n",
            "epoch 2700, loss= 1.2355, acc= 0.672\n",
            "epoch 2800, loss= 1.2942, acc= 0.673\n",
            "epoch 2900, loss= 1.3173, acc= 0.661\n",
            "epoch 3000, loss= 1.3638, acc= 0.674\n",
            "epoch 3100, loss= 1.3288, acc= 0.676\n",
            "epoch 3200, loss= 1.3879, acc= 0.666\n",
            "epoch 3300, loss= 1.4201, acc= 0.679\n",
            "epoch 3400, loss= 1.4103, acc= 0.682\n",
            "epoch 3500, loss= 1.4309, acc= 0.674\n",
            "epoch 3600, loss= 1.5067, acc= 0.676\n",
            "epoch 3700, loss= 1.5022, acc= 0.677\n",
            "epoch 3800, loss= 1.4898, acc= 0.676\n",
            "epoch 3900, loss= 1.5217, acc= 0.673\n",
            "epoch 4000, loss= 1.5275, acc= 0.678\n",
            "test acc=0.678\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDGGZ2i2obw0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}